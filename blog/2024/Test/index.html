<html>
<head>
    <title>Teach Llamas to Talk: Recent Progress in Instruction Tuning</title>
    <meta charset='UTF-8'>
    <meta content='width=device-width, initial-scale=1' name='viewport'/>

    <meta name='description' content="Tianyu Gao\'s website.">
    <meta name='keywords' content='research, llm, instruction-tuning, instruction-following, RLHF'>
    <meta name='author' content='Tianyu Gao'>

    <link rel='shortcut icon' href='/assets/website/website.png' />
    <link href='/css/blog.css' rel='stylesheet'/>
    <link href='/css/trac.css' rel='stylesheet'/>
    <link href='/css/markdown.css' rel='stylesheet'/>

    <script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  jax: ['input/TeX', 'output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['[[', ']]']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    extensions: ['color.js']
  },
  messageStyle: 'none',
  'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'] }
});
</script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body>
<div class='content'>
    <div class='nav'>
    <ul class='wrap'>
        <li><a href='/'>Home</a></li>
        <li><a href='/about'>About</a></li>
        <li><a href='/publications'>Publications</a></li>
        <li><a href='/blog'>Blog</a></li>
        <li><a href='/photography'>Photography</a></li>
    </ul>
</div>
    <div class='front-matter'>
        <div class='wrap'>
            <h1>Teach Llamas to Talk: Recent Progress in Instruction Tuning</h1>
            <h4>Data, algorithms, and evaluation on instruction tuning.</h4>
            <div class='bylines'>
                <div class='byline'>
                    <p>Tianyu Gao</p>
                    <p>30 November 2023</p>
                </div>
            </div>
            <div class='clear'></div>
        </div>
    </div>
    <div class='wrap article'>
        <p><em>Disclaimer: this is not a comprehensive review of instruction-tuning or RLHF literature, but a brief introduction of the recent progress (and a little promotion on our work). However, any comments/suggestions are welcome and please feel free to email me (tianyug@princeton.edu) and I would love to have a discussion!</em></p>

<p>Large language models (LLMs), powered by billions of parameters and trained with trillions of tokens, are quite powerful as they can handle a variety of tasks out of the box. However, to be useful in real-world applications and to act as a general task-solving machine, they must master following user instructions and responding in a coherent and helpful way, instead of being a mere “stochastic parrot”, echoing the chaotic language patterns from the Internet. Thus, open-ended instruction tuning<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> (<a href="https://arxiv.org/abs/2203.02155">Ouyang et al., 2022</a>; InstructGPT), which fine-tunes an LLM such that it can follow user instructions and respond in a helpful, honest, and harmless way (Anthropic’s HHH criteria; <a href="https://arxiv.org/abs/2112.00861">Askell et al., 2021</a>), emerged as a promising approach. The interest further increased after the huge success of ChatGPT. Open-ended instruction tuning usually contains two stages:</p>

